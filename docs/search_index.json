[["index.html", "Data cleaning using R Chapter 1 Data cleaning with R", " Data cleaning using R Yudu Chen Yc4142 2022-11-10 Chapter 1 Data cleaning with R In the real world, the data sets we are handling are often not data scientists can readily use. They might contain duplicate entries when entries are supposed to be unique. They might contain missing values, which is problematic for tasks such as training predicative modeling. The data features might be at vastly different scale, which both induces instability of float point arithmatics and inaccurate measurement of feature importance in training machine learning model. We will discuss how to use R to clean Data sets where situations above take place. We first import libraries we will use: readr package is used to gain a glimpse of data set we will clean. "],["data-we-use.html", "Chapter 2 Data we use", " Chapter 2 Data we use We will explore techniques of data cleaning using “Airquality” dataset from R, which already has some missing values in it. The dataset is available in baseR and does not require import from outside source. library(readr) airQuality_preProcessing &lt;- airquality head(airQuality_preProcessing, 10) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 NA 194 8.6 69 5 10 "],["duplicated-values.html", "Chapter 3 Duplicated Values 3.1 Data set with row-wise duplicates 3.2 Duplicates based on specific columns 3.3 Conclusion", " Chapter 3 Duplicated Values In many cases, we observe duplicated values in a data set where every instances are supposed to be unique. We will now discussed how to handle duplicates. 3.1 Data set with row-wise duplicates Although the dataset we use in this example, airquality data, does not have duplicate, we will use it illustrate the techniques of handling duplicate data. data_duplicated_values = airQuality_preProcessing We see the data set should have no duplicate to begin with. sum(duplicated(data_duplicated_values)) ## [1] 0 Now we randomly pick 5 instances from the dataset to induce duplication for (i in 1: 5) { data_duplicated_values[nrow(data_duplicated_values)+1,] = data_duplicated_values[floor(runif(1, min = 1, max = nrow(data_duplicated_values))),] } We should now have 5 duplicated instances: sum(duplicated(data_duplicated_values)) ## [1] 5 The “duplicated(df)” returns a boolean array where each value at each index indicates if row at the same index in original data set is duplicated or not. We can use ’duplicated(df)” to extract duplicated rows: data_duplicated_values[duplicated(data_duplicated_values),] ## Ozone Solar.R Wind Temp Month Day ## 154 35 NA 7.4 85 8 5 ## 155 NA 332 13.8 80 6 14 ## 156 78 NA 6.9 86 8 4 ## 157 41 190 7.4 67 5 1 ## 158 97 272 5.7 92 7 9 By adding “!” before “duplicated(df)”, we can negate logics in “duplicated(df)” and access non duplicate rows as a data frame: head(data_duplicated_values[!duplicated(data_duplicated_values),], 10) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 NA 194 8.6 69 5 10 There should be no duplicates sum(duplicated(data_duplicated_values[!duplicated(data_duplicated_values),])) ## [1] 0 We can create a new reference to the data set with no duplicates. For the purpose of reusing “data_duplicated_values”, I will just assign the new reference to itself: data_duplicated_values = data_duplicated_values[!duplicated(data_duplicated_values),] Now “data_duplicated_values” should have no duplicates: sum(duplicated(data_duplicated_values)) ## [1] 0 Another way is to use “distinct()” function from tidyverse package. for (i in 1: 5) { data_duplicated_values[nrow(data_duplicated_values)+1,] = data_duplicated_values[floor(runif(1, min = 1, max = nrow(data_duplicated_values))),] } sum(duplicated(data_duplicated_values)) ## [1] 5 data_duplicated_values &lt;- data_duplicated_values %&gt;% distinct() sum(duplicated(data_duplicated_values)) ## [1] 0 3.2 Duplicates based on specific columns Some times duplication of elements in certain column/columns is not desirable. We want to be able to remove rows with duplication in specified columns. We first insert 5 rows with duplicates in “Day” and “Month”, we should see “158” rows after insertion: for (i in 1: 5) { Ozone &lt;- floor(runif(1,min = 0, max = 50)) Solor &lt;- floor(runif(1,min = 0, max = 300)) Wind &lt;- round(runif(1,min = 0, max = 20), 2) Temp &lt;- floor(runif(1,min = 0, max = 20)) random_index = floor(runif(1, min = 1, max = nrow(data_duplicated_values))) Month &lt;- data_duplicated_values[random_index, &#39;Month&#39;] Day &lt;- data_duplicated_values[random_index, &#39;Day&#39;] data_duplicated_values[nrow(data_duplicated_values)+1,] = c(Ozone, Solor, Wind, Temp, Month, Day) } nrow(data_duplicated_values) ## [1] 158 We can remove rows with duplicated “Day” and “Month” combination using “distinct()”. The “.keep_all = TRUE” argument makes sure that for each duplicated combination of Day and Month, we keep the first row for every duplicated combination and we keep all variables in the Data. We should observe the number of rows after dropping dupicated columns going back to “153”, which is the size of data frame before we insert rows with duplicated “Day” and “Month” combinations. data_duplicated_values&lt;- data_duplicated_values %&gt;% distinct(Day, Month, .keep_all = TRUE) nrow(data_duplicated_values) ## [1] 153 3.3 Conclusion We can use “distinct” to remove duplicated rows based on specified columns in data frame. However, we should only drop duplicated columns if we know there should be no duplicated columns in dataset and duplications are likely result of error in data collection. "],["missing-values.html", "Chapter 4 Missing Values 4.1 NA in R 4.2 Impute", " Chapter 4 Missing Values Encountering missing data in dataset is not uncommon. When collecting temperature data the sensor might be broken and unable to measure temperature. When conduct public opinion surveying, the interviewee might forget filling entires on questionaires. Many data science job requires completeness of data, such as training predicative model based on numerical/categorical data. We will now discuss doing data cleaning in R. We will use ‘tidyr’ library for this task: library(tidyr) 4.1 NA in R In R, a missing value is represented by symbol “NA”. head(airquality, 10) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 NA 194 8.6 69 5 10 We can observe, at index 5, the instance has missing value in “Ozone” and “Solar.R” feasure, represented by symbol “NA”. ## Dropping rows with missing data A simple approach is to drop rows with missing data. If our task requires using all features in dataset, we can opt to drop all rows with at least one missing value. However, if our task required using some features, we only need to drop rows with missing values in feastures we specify. We will discuss both cases. ### Drop all rows containing missing Data Suppose we want to use all features in “airquality” dataset and we want to drop all rows with at least 1 missing values. We first check number of rows with missing data in the dataset. The ‘is.na(df)’ command returns a boolean array, where truth value at each index indicate if data element at the same index in data frame df is NA or not. By summing number of “TRUE” values in the ‘is.na(df)’, we know total number of missing values in the data set. sum(is.na(airQuality_preProcessing)) ## [1] 44 We see we have totally 44 missing with at least 1 missing values. To know number of rows with missing value, we use “complete.cases(df)”. The return an array of boolean where boolean value at each index indicate if data instance/case at the corresponding row index in dataset df is complete (having no NA the missing valye) or not. By summing the number of false in the array, we get the total number of rows that has at least 1 missing value. sum(!complete.cases(airQuality_preProcessing)) ## [1] 42 To visualize all rows with missing value: airQuality_preProcessing[!complete.cases(airQuality_preProcessing), ] We now remove rows with na. We use “drop_na()” function from tidyr library to remove all rows with missing values. There are multipe ways to drop rows with missing value, but we will not go exhaustive on this. airQuality_na_droped &lt;- airQuality_preProcessing %&gt;% drop_na() sum(is.na(airQuality_na_droped)) ## [1] 0 nrow(airQuality_na_droped) ## [1] 111 After removing all 42 rows with missing values, we only have 111 rows left, with 42 rows removed from total 153 rows in original data frame. 4.1.1 Drop rows with missing data in specified columns 4.1.1.1 NA in single column We can see dropping all columns with missing data could be wasteful if we don’t use all features in the dataset. For example, if our job does not require feature “Ozone”, we don’t really care if “Ozone” value is missing or not as it is irrelevant to our task. We will explore how to drop rows with na in specific columns. We see “is.na(df)” evaluate presence of NA(missing value) in the entire data set. If we change its argument from df, the entire data set, into a specific column, the function will only evaluate specific columns in the data set and return a boolean array that only reflects presence of missing value at the columns. For example, if we want to see number of rows with missing value in “Ozone” column: sum(is.na(airQuality_preProcessing$Ozone)) ## [1] 37 There are 37 rows with NA in “Ozone” column. To drop rows with missing value in “Ozone”, we put column name “Ozone” as argument: airQuality_na_droped_Ozone &lt;- airQuality_preProcessing %&gt;% drop_na(Ozone) nrow(airQuality_na_droped_Ozone) ## [1] 116 37 rows are extracted from 153 columns, resulting in 116 rows. 4.1.1.2 NA in several columns (And) If we want to drop rows with NA in specific column, for example, rows with NA in both “Ozone” and “Solar.R” columns, we can take advantage of the fact that “is.na(df)” is a boolean array, and we can perform element wise boolean operation in two arrays of same dimension: sum(is.na(airQuality_preProcessing$Ozone) &amp; is.na(airQuality_preProcessing$Solar.R)) ## [1] 2 We see number of rows with missing value in both “Ozone” and “Solar.R” is 2. We now visualize two rows: airQuality_preProcessing[is.na(airQuality_preProcessing$Ozone) &amp; is.na(airQuality_preProcessing$Solar.R), ] ## Ozone Solar.R Wind Temp Month Day ## 5 NA NA 14.3 56 5 5 ## 27 NA NA 8.0 57 5 27 Having the boolean array, we can negate the logics and obtain all rows where we don’t have missing values in “Ozone” and “Solar.R” at the same time. airQuality_NA_Ozone_and_Solor &lt;- airQuality_preProcessing[!(is.na(airQuality_preProcessing$Ozone) &amp; is.na(airQuality_preProcessing$Solar.R)), ] nrow(airQuality_NA_Ozone_and_Solor) ## [1] 151 We have droped two rows from 153 rows in original dataset, so we have 151 rows left. 4.1.1.3 NA in several columns (Or) What if we want to drop columns with NA in “Ozone” or “Solar.R”, such that if any of the two columns contains missing values. We could have used boolean operation between several boolean arrays as we did, but it could be tedious as we have more feastures to consider. We could use “complete.cases()” but use specific columns in dataset as input. The “complete.cases()” returns false if a single column in the rows in data frame we pass in has a missing value, so we could perform “or” operation with it. sum(!(complete.cases(airQuality_preProcessing[,c(&quot;Ozone&quot;,&quot;Solar.R&quot;)]))) ## [1] 42 There are 42 rows with missing values in either “Ozone” or “Solar.R”, or both. In fact, missing values only appear in those two columns, such that we get the total number of rows with missing values in the data set. We can obtain all datas that does not having missing value in “Ozone” or “Solar.R”. airQuality_NA_Ozone_or_Solor&lt;- airQuality_preProcessing[(complete.cases(airQuality_preProcessing[,c(&quot;Ozone&quot;,&quot;Solar.R&quot;)])), ] nrow(airQuality_NA_Ozone_or_Solor) ## [1] 111 We have 111 rows after removing 42 rows with missing value on either “Ozone” or “Solar.R” We can also use drop_na() to with columns specified in function arguement: airQuality_NA_Ozone_or_Solor&lt;- airQuality_preProcessing %&gt;% drop_na(c(&quot;Ozone&quot;, &quot;Solar.R&quot;)) nrow(airQuality_NA_Ozone_or_Solor) ## [1] 111 4.1.1.4 Drop columns with certain number of NA This might be uncommon, but we might want to drop rows with more than certain number of NA, such as rows with more than 3 NA and even rows with number of NA equal to number of columns, which means the row has all column value being NA. To know number of NA in each row, we can use “rowSums()” functions: head(rowSums(is.na(airQuality_preProcessing)),10) ## [1] 0 0 0 0 2 1 0 0 0 1 This means for row 1 to row 10, row 5 has 2 NA and row 6 and 10 has 1 NA. We can drop all rows with number of NA above certain threshold. We now insert 3 rows with 3 NA into the data frame. airQuality_3NA_Inserted &lt;- airQuality_preProcessing for (i in 1: 3) { Ozone &lt;- floor(runif(1,min = 0, max = 50)) Solor &lt;- floor(runif(1,min = 0, max = 300)) Wind &lt;- round(runif(1,min = 0, max = 20), 2) Temp &lt;- floor(runif(1,min = 0, max = 20)) random_index = floor(runif(1, min = 1, max = nrow(airQuality_3NA_Inserted))) Month &lt;- airQuality_3NA_Inserted [random_index, &#39;Month&#39;] Day &lt;- airQuality_3NA_Inserted [random_index, &#39;Day&#39;] toInsert &lt;- c(Ozone, Solor, Wind, Temp, Month, Day) for (i in 1:3) { random_index = floor(runif(1, min = 1, max = 6)) if (is.na(toInsert[random_index])) { random_index = floor(runif(1, min = 1, max = 6)) } toInsert &lt;- replace(toInsert, random_index, NA) } airQuality_3NA_Inserted [nrow(airQuality_3NA_Inserted )+1,] &lt;- toInsert } tail(airQuality_3NA_Inserted, 3) ## Ozone Solar.R Wind Temp Month Day ## 154 NA 296 NA 11 NA 26 ## 155 NA 52 2.8 4 NA 5 ## 156 NA 134 NA 0 NA 26 print(paste(&#39;number of rows in airQuality_3NA_Inserted is&#39;, nrow(airQuality_3NA_Inserted))) ## [1] &quot;number of rows in airQuality_3NA_Inserted is 156&quot; Now last 3 rows have 3 NA at tail of airQuality_3NA_Inserted. We now check number of rows with more than or equal to 3 NA: print(paste0(&quot;number of rows with at least 3 NA in airQuality_3NA_Inserted is &quot;, sum(rowSums(is.na(airQuality_3NA_Inserted)) &gt;= 3))) ## [1] &quot;number of rows with at least 3 NA in airQuality_3NA_Inserted is 2&quot; Now we have 3 rows with at least 3 NA. We now drop rows with at least 3 NA from airQuality_3NA_Inserted by selecting rows with NA less than 3 and reset reference of airQuality_3NA_Inserted: airQuality_3NA_Inserted &lt;- airQuality_3NA_Inserted[!(rowSums(is.na(airQuality_3NA_Inserted)) &gt;= 3), ] print(paste0(&quot;number of rows in airQuality_3NA_Inserted after dropping is &quot;, nrow(airQuality_3NA_Inserted))) ## [1] &quot;number of rows in airQuality_3NA_Inserted after dropping is 154&quot; We have drop all 3 rows with at least 3 NA, so the size of airQuality_3NA_Inserted drops from 156 to 153. 4.2 Impute Dropping rows is a straight forward approach. However, dropping too many drows would induce huge data loss, which would be detrimental to our task. We can insert values we specify into entries with missing values. This will minimize data loss. Though we would never know if imputed values could reflect the true pattern of the data. We first install package we will use: 4.2.1 Numerical 4.2.1.1 Impute with constant For a column with missing value,we select a constant we think will reflect the real data and fill missing entry in the column with the constant we have selected. Let’s say we use constant 30 to fill “Ozone” entries with missing values. airQuality_const_filled &lt;- airQuality_preProcessing print(paste0(&quot;number of missing values in Ozone column is &quot;, sum(is.na(airQuality_const_filled$Ozone)))) ## [1] &quot;number of missing values in Ozone column is 37&quot; head(airQuality_const_filled , 5) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 We now fill: airQuality_const_filled$Ozone &lt;- na_replace(airQuality_const_filled$Ozone, fill = 30, maxgap = Inf) print(paste0(&quot;number of missing values in Ozone column is &quot;, sum(is.na(airQuality_const_filled$Ozone)))) ## [1] &quot;number of missing values in Ozone column is 0&quot; head(airQuality_const_filled , 5) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 30 NA 14.3 56 5 5 We see NA in Ozone column of row 5 is imputed by constant 30. Pro Easy to understand. Con Value assigned by human intuition is too arbitrary and might be unrealistic. 4.2.1.2 Impute with Sample statistics We can impute missing values in a column using sample statistics of the columns such as mean and median. This way we fill the missing value and does not alter data statistics in the column. We now fill “Ozone” column with current “Mean” of “Ozone” column and “Solar.R” with median of “Solar.R” column. Note the “na.rm = True” arguement is to neglect missing value when computing sample statistics so that we get a real value answer. airQuality_sstat_impute &lt;- airQuality_preProcessing print(paste0(&quot;Mean of Ozone before impute is &quot;, mean(airQuality_sstat_impute$Ozone, na.rm = TRUE))) ## [1] &quot;Mean of Ozone before impute is 42.1293103448276&quot; print(paste0(&quot;Median of Solar.R before impute is &quot;, median(airQuality_sstat_impute$Solar.R, na.rm = TRUE))) ## [1] &quot;Median of Solar.R before impute is 205&quot; print(paste0(&quot;number of missing values in Ozone column before impute is &quot;, sum(is.na(airQuality_sstat_impute$Ozone)))) ## [1] &quot;number of missing values in Ozone column before impute is 37&quot; print(paste0(&quot;number of missing values in Solar.R column before impute is &quot;, sum(is.na(airQuality_sstat_impute$Solar.R)))) ## [1] &quot;number of missing values in Solar.R column before impute is 7&quot; airQuality_sstat_impute$Ozone &lt;- na_mean(airQuality_sstat_impute$Ozone, option = &quot;mean&quot;, maxgap = Inf) airQuality_sstat_impute$Solar.R &lt;- na_mean(airQuality_sstat_impute$Solar, option = &quot;median&quot;, maxgap = Inf) print(&#39; &#39;) ## [1] &quot; &quot; print(paste0(&quot;Mean of Ozone after impute is &quot;, mean(airQuality_sstat_impute$Ozone))) ## [1] &quot;Mean of Ozone after impute is 42.1293103448276&quot; print(paste0(&quot;Median of Solar.R after impute is &quot;, median(airQuality_sstat_impute$Solar.R))) ## [1] &quot;Median of Solar.R after impute is 205&quot; print(paste0(&quot;number of missing values in Ozone column after impute is &quot;, sum(is.na(airQuality_sstat_impute$Ozone)))) ## [1] &quot;number of missing values in Ozone column after impute is 0&quot; print(paste0(&quot;number of missing values in Solar.R column after impute is &quot;, sum(is.na(airQuality_sstat_impute$Solar.R)))) ## [1] &quot;number of missing values in Solar.R column after impute is 0&quot; We see we no longer have missing values in both columns and mean in “Ozone” column and median in “Solar.R” are both unchanging from before the impute. Pro Easy to understand. Does not change sample statistics Con Maybe the distribution of valid values in columns are skewed to left or right or have many outliers such that sample statistics do not reflect actual pattern of data 4.2.1.3 Impute by value adjacent to Missing value Often in time-series data, value on a time point is highly assosicated with most adjacent valid values. Therefore, we want to fill a missing entries using valid data values before or after it. airQuality_Adjacent_impute &lt;- airQuality_preProcessing head(airQuality_Adjacent_impute, 10) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 NA 194 8.6 69 5 10 print(&#39;We first fill missing values in Ozone column with last observed valid value&#39;) ## [1] &quot;We first fill missing values in Ozone column with last observed valid value&quot; airQuality_Adjacent_impute$Ozone &lt;- na_locf(airQuality_Adjacent_impute$Ozone, option = &quot;locf&quot;) print(&#39;We then fill missing values in Solar.R column with next observed valid value&#39;) ## [1] &quot;We then fill missing values in Solar.R column with next observed valid value&quot; airQuality_Adjacent_impute$Solar.R &lt;- na_locf(airQuality_Adjacent_impute$Solar.R, option = &quot;nocb&quot;) head(airQuality_Adjacent_impute, 10) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 18 299 14.3 56 5 5 ## 6 28 299 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 8 194 8.6 69 5 10 If we have missing value at beginning or end of data frame, which is rare, we can remedy using “na_remaining” argument in “na_locf()” to handle remaining missing value after filling. More details can be found in imputeTS documentation. Pro For time series data, using adjacent value that are close could capture time dependent pattern Con If cloested adjacent value is too far away, filling adjacent value would not sustain time dependent pattern. 4.2.1.4 Impute using predicative model If we believe certain features in the data frame depends on some other features, we can use other features to fit a predicative model to predict missing value in certain feature. We need to make sure the “other features” our prediction is based on are all valid entries, which we need to impute using some method. We now assume “Ozone” and “Solar.R” features depends on climate related features such as “Wind” and “Temperature”, and we build linear regression models for “Ozone” and “Solar.R” based on “Wind” and “Temperature”. airQuality_lm_impute &lt;- airQuality_preProcessing head(airQuality_lm_impute, 10) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 NA NA 14.3 56 5 5 ## 6 28 NA 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 NA 194 8.6 69 5 10 print(paste0(&#39;number of missing values in Ozone column before impute is &#39;, sum(is.na(airQuality_lm_impute$Ozone)))) ## [1] &quot;number of missing values in Ozone column before impute is 37&quot; print(paste0(&#39;number of missing values in Solar.R column before impute is &#39;, sum(is.na(airQuality_lm_impute$Solar.R)))) ## [1] &quot;number of missing values in Solar.R column before impute is 7&quot; linear_model_Ozone &lt;- lm(Ozone ~ Wind + Temp, data = airQuality_lm_impute) linear_model_Solar.R &lt;- lm(Solar.R ~ Wind + Temp, data = airQuality_lm_impute) airQuality_lm_impute$Ozone[is.na(airQuality_lm_impute$Ozone)] &lt;- predict(linear_model_Ozone, newdata = airQuality_lm_impute[is.na(airQuality_lm_impute$Ozone),c(&#39;Wind&#39;, &#39;Temp&#39;)]) airQuality_lm_impute$Solar.R[is.na(airQuality_lm_impute$Solar.R)] &lt;- predict(linear_model_Solar.R, newdata = airQuality_lm_impute[is.na(airQuality_lm_impute$Solar.R),c(&#39;Wind&#39;, &#39;Temp&#39;)]) head(airQuality_lm_impute, 10) ## Ozone Solar.R Wind Temp Month Day ## 1 41.00000 190.0000 7.4 67 5 1 ## 2 36.00000 118.0000 8.0 72 5 2 ## 3 12.00000 149.0000 12.6 74 5 3 ## 4 18.00000 313.0000 11.5 62 5 4 ## 5 -11.67673 127.4317 14.3 56 5 5 ## 6 28.00000 159.5042 14.9 66 5 6 ## 7 23.00000 299.0000 8.6 65 5 7 ## 8 19.00000 99.0000 13.8 59 5 8 ## 9 8.00000 19.0000 20.1 61 5 9 ## 10 29.66190 194.0000 8.6 69 5 10 Since the original data are integer, We now convert “Ozone” and “Solar.R” back to integer from double. airQuality_lm_impute$Ozone &lt;- as.integer(airQuality_lm_impute$Ozone) airQuality_lm_impute$Solar.R &lt;- as.integer(airQuality_lm_impute$Solar.R) head(airQuality_lm_impute, 10) ## Ozone Solar.R Wind Temp Month Day ## 1 41 190 7.4 67 5 1 ## 2 36 118 8.0 72 5 2 ## 3 12 149 12.6 74 5 3 ## 4 18 313 11.5 62 5 4 ## 5 -11 127 14.3 56 5 5 ## 6 28 159 14.9 66 5 6 ## 7 23 299 8.6 65 5 7 ## 8 19 99 13.8 59 5 8 ## 9 8 19 20.1 61 5 9 ## 10 29 194 8.6 69 5 10 linear_model_Ozone ## ## Call: ## lm(formula = Ozone ~ Wind + Temp, data = airQuality_lm_impute) ## ## Coefficients: ## (Intercept) Wind Temp ## -71.033 -3.055 1.840 linear_model_Solar.R ## ## Call: ## lm(formula = Solar.R ~ Wind + Temp, data = airQuality_lm_impute) ## ## Coefficients: ## (Intercept) Wind Temp ## -76.362 2.211 3.075 We have now filled missing values using linear regresison model prediction from valid values from other columns. ## [1] &quot;number of missing values in Ozone column after impute is 0&quot; ## [1] &quot;number of missing values in Solar.R column after impute is 0&quot; "],["interactive-component.html", "Chapter 5 Interactive component", " Chapter 5 Interactive component "],["conclusion-1.html", "Chapter 6 Conclusion", " Chapter 6 Conclusion "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
